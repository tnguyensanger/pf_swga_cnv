Building DAG of jobs...
Using shell: /usr/local/bin/bash
Provided cluster nodes: 1
Job counts:
	count	jobs
	1	all
	1	call_cnv
	1	mean_rd
	1	output_cnv_csv
	4

rule call_cnv:
    input: /lustre/scratch118/malaria/team112/personal/tn6/pf_swga_cnv_wgs/output/xhmm/xhmm_test.PCA_normalized.filtered.sample_zscores.RD.txt, /lustre/scratch118/malaria/team112/personal/tn6/pf_swga_cnv_wgs/output/xhmm/xhmm_test.same_filtered.RD.txt
    output: /lustre/scratch118/malaria/team112/personal/tn6/pf_swga_cnv_wgs/output/xhmm/xhmm_test.xcnv
    jobid: 3

Submitted job 3 with external jobid 'Job <3024567> is submitted to queue <normal>.'.
Terminating processes on user request, this might take some time.
Will exit after finishing currently running jobs.
Complete log: /nfs/users/nfs_t/tn6/gitrepo/pf_swga_cnv/src/shell/.snakemake/log/2018-06-27T072812.030555.snakemake.log
